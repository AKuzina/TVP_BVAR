% !Rnw root = Main.Rnw
\subsection{Методология} \label{sec:method}
В данном разделе будет описан процесс построения моделей: выбор спецификаций, оценка коэффициентов, получение прогнозов, а также методы сравнения качества полученных прогнозов, которые использовались в данной работе. Заметим также, что методология для макроэкономических данных и для акций будет иметь некоторые различия.

\subsubsection{Построение прогноза одномерных моделей}
Одномерные модели: ARIMA, экспоненциальное сглаживание и тета-\\метод, строятся для всех типов данных. Для этого используются функции пакета \texttt{forecast}, предоставляющие возможность автоматического выбора оптимальной спецификации. Они используют алгоритмы, описанные в разделах \ref{sec:ets}-\ref{sec:teta} данной работы. 

Далее строится гибридный прогноз. В этих целях для каждого ряда определяются те однмерные модели, которые имеют меньшую среднеквадратичную ошибку на тестовой выборке чем модель случайного блуждания. Однако, оказалось, что для нескольких временных рядов такая модель только одна. В таких случае было решено строить гибридный прогноз по всем трем одномерным моделям. 

Существует несколько способов получения гибридного прогноза. Самый простой --- использовать среднее арифметическое имеющихся прогнозов. Даже такой простой шаг помогает в среднем улучшить качество прогнозов \footnote{см. статью Bates and Granger, The Combination of Forecasts (1969)}. Более ресурсоемкий (в вычислительном плане), но при этом показавший лучшие результаты, подход --- использование кросс-валидации для расчета ошибки модели на тренировочной выборке. В работе использовался именно этот подход, поэтому рассмотрим подробнее принцип его работы.

Так как мы имеем дело с временными рядам, у нас нет возможности исключать наблюдения случайным образом и строить модель на оставшихся данных. Поэтому кросс-валидация для временных рядов подразумевает использование скользящего окна. Принцип работы данного метода заключается в следующем: выбирается фиксированное число наблюдений $n < N$, где $N$ --- размер тренировочной выборки, а также горизонт прогноза $h$. Используя $n$ первых наблюдений оценивается интересующая нас модель и строится прогноз на $h$ периодов вперед. Затем, мы <<сдвигаемся>> на $h$ периодов вперед, оцениваем модель на наблюдениях $h:h+n$ и снова строим прогноз. Процедура повторяется до тех пор, пока мы не получим прогнозы для всех наблюдений тестовой выборки, кроме первых $n$.

Используя полученные значения, считается ошибка прогноза. Например, его среднеквадратичное отклонение от действительного значения переменной (RMSE). Получив ошибку на тренировочной выборке, для каждой модели, используемой для построения гибридного прогноза, считаются веса по следующей формуле:
\begin{equation}\label{hybridWeights}
w_i = \frac{\frac{1}{RMSE_i}}{\sum_{j=1}^{k}\frac{1}{RMSE_j}},
\end{equation}
где $k$ --- общее число моделей. Заметим, что чем больше ошибка на тестовой выборке, тем меньший вес будет иметь модель при построении гибридного прогноза. Полученные из уравнения \eqref{hybridWeights} веса присваиваются прогнозам разных моделей и таким образом получается гибридный прогноз.

В результате, применяя описанную выше методологию, для каждого временного ряда мы рассчитываем 4 разных прогноза с использованием одномерных моделей. 

\subsubsection{Построение прогноза TVP-BVAR}
В первую очередь, в рамках каждого из двух наборов данных были выбраны группы переменных, которые впоследствии использовались для построения байсовских векторных авторегрессий с переменными параметрами. В связи с ограничениями пакета \texttt{bvarsv}, с помощью которого реализовано построение моделей TVP-BVAR, оценить параметры векторной авторегресси можно только для ограниченного числа переменных и лагов. Как уже упоминалось выше, включение каждой последующей переменной или увеличение числа лагов приводит к значительному росту количества оцениваемых параметров, что становится причиной возникновению ошибок в алгоритме семплирования. Именно поэтому в рамках данного исследование не было возможности построить многомерную модель, включающую в себя все временных ряды из набора данных.

Важным критерием для определения таких групп является <<схожесть>> переменных между собой. Для векторной авторегрессии большую роль играет совместная динамика переменных, поэтому нет смыла включать в модель переменные, которые совершенно не связаны между собой. Руководствуясь данным предположением, для финансового набора данных было решено строить отдельные модели для каждой индустрии. Логично предположить, что крупнейшие компании одной индустрии могут быть подвержены одним и тем же внешним шокам, более того, шоки, влияющие на одну компанию могут влиять на ожидания игроков финансового рынка относительно других компаний данной индустрии и, следовательно, приводить к колебаниям цен на акции всех компаний. Таким образом, было построено 8 TVP-BVAR моделей для финансового набора данных, в каждом из которых использовалось по 4 лага. 

В случае с макроэкономическими данными гораздо сложнее выделить группы наиболее тесно связанных переменных. Поэтому в работе использовался метод поиска схожих объектов (переменных) путем снижения размерности данных --- t-SNE (\EN{t-distributed Stochastic Neigbour Embedding}). Для поиска оптимального пространства малой размерности в данном методе сначала определяется коэффициенты схожести всех точек исходного пространства --- $p_{i,j}$. Этот коэффициент зависит от расстояния между этими точками  $D_{i,j}$ и считается следующим образом:
\begin{align*}
p_{j|i} &= \frac{\exp(-\|D_{i,j}\|^2 / 2 \sigma_i^2)}{∑_{k \neq i} \exp(-\|D_{i,k}\|^2 / 2 \sigma_i^2)}\\
p_{i,j} &=\frac{p_{j|i} + p_{i|j}}{2n}
\end{align*}
Параметр $\sigma$ выбирается таким образом, чтобы перплексивность случайной величины $p_{i|j}$ была близка к указанному пользователем значению. Фактически, параметр перплексивности контролирует эффективное число <<соседей>> точки i, которые имеют значимый вес при переходе в пространство меньшей размерности. В пространстве низкой размерности расстояния между точками имеют распределение Стьюдента с 1 степенью свободы (отсюда и название метода) и рассчитываются следующим образом:\\
\begin{equation*}
q_{i,j} = \frac{(1+ \| y_i-y_j\|^2)^{-1}}{∑_{k \neq l} 1+ \| y_k-y_l\|^2)^{-1}}
\end{equation*}
Положение точек в новом пространстве определяется так, чтобы получить как можно более схожие значение $q_{i,j}$ и $p_{i,j}$.

На рисунке \ref{fig:team.plots} представлены результаты применения данного алгоритма к макроэкономическим данным.
<<macro teams, echo=FALSE>>=
set.seed(7)
macro.pc <- Rtsne(t(macro), dims = 2, perplexity = 2)
@
<<team.plots, echo=FALSE, fig.height=7, fig.width=12, fig.cap='Макроэкономические данные, деление на кластеры', fig.lp='fig:', fig.pos = 'h'>>=
qplot(x = macro.pc$Y[,1], y = macro.pc$Y[,2]) + 
  annotate("text", x = macro.pc$Y[,1], y = macro.pc$Y[,2],  label = m.names) +
  annotate("rect", xmin = -175, xmax = -25, ymin = -75, ymax = 25,
           alpha = .15)+
  annotate("rect", xmin = 50, xmax = 250, ymin = -75, ymax = -15,
           alpha = .15)+
  annotate("rect", xmin = -200, xmax = -125, ymin = 100, ymax = 135,
           alpha = .15)+
  ylab("Компонента 1")+
  xlab("Компонента 1")+
    theme(text = element_text(size=22))
@

 В результате снижения размерности данных до двух наблюдений мы получили три явных кластера. Построим 6 разных моделей - для каждого кластера отдельно, а также для всех комбинаций двух кластеров между собой. Количество лагов для каждой модели выбиралось с учетом ограничений статистического пакета \texttt{bvarsv}. Так, для больших моделей, в которые вошли данные двух кластеров, использование более чем одного лага приводило к возникновению ошибок. В таблице \ref{table:macro.tvp} представлены спецификации всех построенных в результате моделей.
 \begin{center*}
\begin{table}[h]
\renewcommand{\arraystretch}{1.3}
\begin{threeparttable}
\centering
\caption{TVP-BVAR модели для макроэкономических рядов}
\label{table:macro.tvp}
\begin{tabularx}{\textwidth}{lXX}
\toprule
Переменные                                                &  Количество лагов  & Название    \\ \midrule
y, $\pi$, r, u, m, $\text{e}_{doll}$, w    &  1  &   TVP-B1  \\
y, m, w, rts, oil                          &  1  &   TVP-B2  \\
$\pi$, r, u, $\text{e}_{doll}$, rts, oil   &  1  &   TVP-B3  \\
\multirow{2}{*}{y, m, w}       &  6  &   TVP-S6  \\
                                                              &  3  &   TVP-S3  \\
\multirow{3}{*}{rts, oil}     &  12 &   TVP-S12  \\
                                                              &  6  &   TVP-S6 \\
                                                              &   3  &   TVP-S3  \\
\multirow{2}{*}{$\pi$, r, u, $\text{e}_{doll}$} &  3  &   TVP-S3  \\
                                                              &   1  &   TVP-S1  \\ \bottomrule
\end{tabularx}
\begin{tablenotes} 
      \item Источник: Расчеты автора
\end{tablenotes}
\end{threeparttable}
\end{table}
\end{center*}

При построении моделей с использованием байесовского подхода важным этапом является выбор количества итераций, так как от этого сильно зависит качество полученных результатов. На первых шагах алгоритма семплирования выборка достаточна далека от истинного апостериорного распределения и количество итераций должно быть достаточно большим, чтобы полученная марковская цепь <<сошлась>> к своему стационарному состоянию. Для того, чтобы не получать искаженные оцени, в результирующую выборку не включают первую часть полученных случайных значений. Считается, что эти итерации служат для <<прожига>> (burn - in) Марковского процесса. К сожалению, нельзя точно проверить или оценить степень сходимости цепи, однако есть критерии, которые помогают идентифицировать отсутствие сходимости, основной из которых --- наличие высокой и устойчивой автокорреляции в полученной выборке. Для снижения вероятности получения цепи с высокой автокорреляцией часто не только исключают первые итерации, но и <<прореживают>> оставшиеся элементы, выбирая только каждый второй, пятый или даже десятый элемент.

При построении модели TVP-BVAR генерируется марковская цепь с очень большим числом звеньев (значений). Так, в модели, построенной для макроэкономических данных с пятью переменными и 1 лагом (TVP-B2), количество сгенерированных выборок итоговых коэффициентов модели и элементов ковариационных матриц остатков составляет 7645, то есть 55 выборок для каждого их 139 моментов времени, 25 из которых представляют собой элементы ковариационной матрицы остатков, а 30 --- коэффициенты модели (5 уравнений с 5 объясняющими переменными и одним свободным коэффициентом в каждом). В результате, проверка сходимости каждой цепи связано с очень высокими трудозатратами, поэтому было принято решение проверить сходимость 4170 цепей в описанной выше модели, с использованием различного количества итераций.

В результате было обнаружено, что при использовании 5000 итераций для <<розжига>> и включения в итоговую выборку каждого 10-го элемента цепи из 20000 случайно сгенерированных элементов, автокорреляция 20-го порядка в каждой из более чем четырех тысяч цепей крайне редко превосходит значение 0.1, что показано на рисунке \ref{fig:autocorr_plot}. Опираясь на данные результаты, последующие байесовские векторные авторегрессии оценивались с таким же количеством итераций.

<<autocorr compute,echo = FALSE>>=
autocorr <- read.csv("autocorr.csv")
@
<<autocorr_plot, echo = FALSE, fig.height=6, fig.width=12, fig.cap='Автокорреляция для параметров модели TVP-B2', fig.lp='fig:', fig.pos='h'>>=
qplot(x = autocorr[,1], y = autocorr[,2], geom = 'line')+
  xlab("Параметры модели")+
  ylab("Автокорреляция 20-го порядка")+
  theme(text = element_text(size = 22))
@

\subsubsection{Сравнение прогнозов}

Прогнозы, полученные в результате, сравниваются на основании отношения среднеквадратичной ошибки прогноза данной модели к среднеквадратичной ошибке прогноза случайного блуждания. То есть ошибка i-ой модели в прогнозировании k-ой переменной на горизонте h рассчитывается следующим образом:\\
\begin{align*}
Error^{(i)}_{k,h} &= \frac{RMSE^{(i)}_{k,h}}{RMSE^{(RW)}_{k,h}}, \quad \text{где}\\
RMSE^{(i)}_{k,h} &= \sqrt{\frac{1}{h}\sum_{j=1}^{h}(y_{T+j}-\hat{y}_{T+j})^2}
\end{align*}

Модель случайного блуждания предполагает, что лучший прогноз всех будущих значений ряда --- это последнее известное наблюдения. Такой прогноз еще называют наивным. В следующей части работы будут представлены полученные результаты оценки моделей и проведено сравнение качества прогнозов.

